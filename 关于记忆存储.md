这三个文件通过分工合作，实现了一个完整的**RAG（检索增强生成）存储流程**。简单来说，它们将文件夹里的文本文件“切碎”、转换成“数字（向量）”，然后分别存入**SQLite数据库**（存文本内容）和**HNSW索引文件**（存向量数据）。

以下是具体的流程分析：

### 1. 发现与读取：`VectorDBManager.js` (总管)

这个文件是整个系统的核心调度器，负责监控文件变化并安排处理任务。

* **监听文件夹**: 通过 `watchDiaries()` 方法使用 `chokidar` 库监听 `dailynote` 文件夹。一旦发现 `.txt` 或 `.md` 文件有变动（新增、修改、删除），它会触发更新流程。
* **计算差异**: 在 `calculateChanges` 方法中，它会对比文件的哈希值（Hash），判断哪些文件是新的，哪些内容变了，从而决定只处理变动的部分（增量更新），而不是每次都重读所有文件。
* **文本切片**: 读取到的长文本会被 `chunkText` 函数切分成一个个小的片段（Chunk），例如每 500 字一段，以便后续处理。

### 2. 向量化（转化成数字）：`VectorDBManager.js` (加工厂)

这是将“文字”变成“计算机能理解的数字”的关键步骤。

* **调用 API**: 在 `getEmbeddingsInWorker` 或 `getEmbeddingsWithRetry` 方法中，切分好的文本片段会被发送给 Embedding API（如 OpenAI 或本地模型）。
* **生成向量**: API 返回一组浮点数数组（例如 `[0.123, -0.456, ...]`），这组数字代表了这段文字的**语义**。

### 3. 存储（存入大脑）：双轨制存储

系统使用了**双轨制存储**，分别由两个文件负责：

#### A. 存文本与关系：`VectorDBStorage.js` (档案室)
这个文件管理 **SQLite 数据库** (`vectordb.sqlite`)。它不存向量检索用的数学结构，而是存储“原始内容”和“元数据”。

* **表结构**:
    * `files` 表：记录文件名和对应的哈希值（用于判断文件是否修改）。
    * **`chunks` 表（核心）**：这里存储了切片后的**原文内容 (`text`)**、来源文件 (`source_file`)、以及一个对应的 ID (`label`)。
* **作用**: 当你检索到一个向量时，系统通过 ID 来这里找回它是哪段话、在哪篇日记里。

#### B. 存向量索引：`VectorDBManager.js` (索引库)
这个文件管理 **HNSW 索引文件** (`.bin` 文件，位于 `VectorStore` 目录下)。

* **构建索引**: 它使用 `hnswlib-node` 库，将第 2 步生成的**向量数组**添加到 HNSW 索引结构中。
* **关联 ID**: 在添加向量时，会传入一个 `label`（整数 ID）。这个 ID 与 `VectorDBStorage.js` 里的 `chunks` 表的 ID 是**一一对应**的。
* **持久化**: 最后通过 `index.writeIndex(indexPath)` 将索引保存为二进制文件。

### 4. 标签增强：`VectorDBManager_TagExtension.js` (辅助索引)

这个文件是可选的增强模块。

* **提取标签**: 它会扫描文本块中是否包含 `Tag: xxx` 格式的内容。
* **独立存储**: 它会调用 `TagVectorManager` 将这些标签单独向量化并存储。
* **融合搜索**: 在搜索时，它不仅比对正文的向量，还会比对标签的向量（Alpha-Beta 融合算法），让检索更精准。

### 总结流程图

1.  **`VectorDBManager.js`**: 发现 `2023.txt` 变动 -> 读取内容 -> 切成 3 段 -> 找 API 算出 3 个向量。
2.  **`VectorDBStorage.js`**: 将这 3 段**文字**和**文件名**存入 SQLite 数据库，分配 ID 为 101, 102, 103。
3.  **`VectorDBManager.js`**: 将这 3 个**向量**连同 ID (101, 102, 103) 存入 HNSW 索引文件 (`.bin`)。
4.  **`VectorDBManager_TagExtension.js`**: 如果某段文字里有 `Tag: 开心`，额外把“开心”这个标签也存起来用于加权。